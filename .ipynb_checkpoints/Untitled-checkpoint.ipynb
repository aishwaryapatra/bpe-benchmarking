{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpemb_en=BPEmb(lang=\"en\",dim=50)\n",
    "input= \"Stanford is a nice place\"\n",
    "print(bpemb_en.encode(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bpemb_en.embed(input).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from bpemb import BPEmb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bpemb_en=BPEmb(lang=\"en\",dim=50)\n",
    "le=preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.csv') as f:\n",
    "    reader=csv.reader(f,delimiter='\\t')\n",
    "    max_len=0\n",
    "    y=[]\n",
    "    for row in tqdm(reader):\n",
    "        y.append(row[1])\n",
    "        sample_len=len(bpemb_en.encode(row[0]))\n",
    "        max_len=sample_len if sample_len > max_len else max_len\n",
    "\n",
    "max_len=max_len+1\n",
    "print(max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_labels=le.fit_transform(y)\n",
    "print(le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=to_categorical(encoded_labels,num_classes=len(le.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x= None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train.csv','r') as f:\n",
    "    reader=csv.reader(f,delimiter='\\t')\n",
    "    for row in tqdm(reader):\n",
    "        embeddings=bpemb_en.embed(row[0])\n",
    "        padding_vec=np.zeros((max_len - embeddings.shape[0],50))\n",
    "        padded=np.vstack((embeddings,padding_vec))\n",
    "        padded=np.expand_dims(padded,axis=0)\n",
    "        print(padded.shape)\n",
    "        if x is not None:\n",
    "            x=np.vstack((x,padded))\n",
    "        else:\n",
    "            x=padded\n",
    "print(x.shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense,Dropout,Activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D,GlobalMaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.matrices import confusion_matrix,classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embedding_dims = 50\n",
    "filters = 250\n",
    "kernel_size = 3\n",
    "\n",
    "hidden_dims = 250\n",
    "epochs = 200\n",
    "bpemb_dims = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test= None\n",
    "y_test= []\n",
    "with open(\"test.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    for row in tqdm(reader):\n",
    "        embeddings = bpemb_en.embed(row[0])\n",
    "        y_test.append(row[1])\n",
    "        padding_vec = np.zeros((max_len - embeddings.shape[0], bpemb_dims))\n",
    "        padded = np.vstack((embeddings, padding_vec))\n",
    "        padded = np.expand_dims(padded, axis=0)\n",
    "        if x_test is not None:\n",
    "            x_test = np.vstack((x_test, padded))\n",
    "        else:\n",
    "            x_test = padded\n",
    "y_test_enc = le.transform(y_test)\n",
    "y_test = to_categorical(y_test_enc, num_classes=len(le.classes_))\n",
    "print(x_test.shape, y_test.shape)\n",
    "print('Build model...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# we add a Convolution1D, which will learn filters\n",
    "# word group filters of size filter_length:\n",
    "model.add(Conv1D(filters,\n",
    "                 kernel_size,\n",
    "                 padding='valid',\n",
    "                 activation='relu',\n",
    "                 strides=1))\n",
    "# we use max pooling:\n",
    "model.add(GlobalMaxPooling1D())\n",
    "\n",
    "# We add a vanilla hidden layer:\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
    "model.add(Dense(len(le.classes_)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x, y,\n",
    "          batch_size=batch_size,\n",
    "epochs=epochs, validation_split=0.1)\n",
    "pred=model.predict(x_test)\n",
    "print(confusion_matrix(np.argmax(y_test,axis=1,np.argmax(x_test,axis=1))))\n",
    "print(classification_report(np.argmax(y_test,axis=1,np.argmax(x_test,axis=1))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
